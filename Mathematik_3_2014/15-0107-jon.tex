 %8.3 - 8.9 % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 8.3\subsection{Definition}F"ur $A \in M_n(K)$ heißt $p_a(\lambda):=det(A-\lambda \cdot E_n)$ das \emph{charakteristische Polynom} von $A$.% % % 8.4\subsection{Beispiel}$A=\begin{pmatrix}1 & 1 \\ -2 & 4\end{pmatrix} \in M_2(\mathbb{R}$\\Eigenwerte, Eigenvektoren, Eig(A), $p_A(\lambda)$?$A-\lambda\cdot E_2 = \begin{pmatrix}1 & 1 \\ -2 & 4\end{pmatrix}-\lambda\cdot \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix} = \begin{pmatrix}1-\lambda & 1\\ -2 & 4-\lambda\end{pmatrix}$\begin{itemize}	\item	$p_A(\lambda)=\mathrm{det}\begin{pmatrix}1-\lambda & 1 \\ -2 & 4-\lambda\end{pmatrix} = (1-\lambda)(4-\lambda)-(1\cdot (-2)) = \lambda^2-5\lambda+6 = (\lambda-2)(\lambda-3)$		\item	Eigenwerte von A:\\	$\lambda\in W$ von A $\stackrel{8.2}{\Leftrightarrow} p_A(\lambda)=0 \Leftrightarrow \lambda=2$ oder $\lambda=3$\\	$\Rightarrow \lambda_1=2, \lambda_2=3$ Eigenwerte von A		\item	Eigenvektoren von A:\\	x ist EV von A zum EW $\lambda_1 \Leftrightarrow x\neq \mathcal{O}$ und $(A-\lambda_1E_2)x=\mathcal{O}$		also $\begin{pmatrix}1-2 & 1 \\ -2 & 4-2\end{pmatrix}x=\begin{pmatrix}0 \\ 0\end{pmatrix} \Leftrightarrow \begin{pmatrix}-1 & 1 \\ -2 & 2\end{pmatrix}\begin{pmatrix}x_1 \\ x_2\end{pmatrix}=\begin{pmatrix}0 \\ 0\end{pmatrix}$\\	$\begin{pmatrix}-1 & 1 & | & 0 \\ -2 & 2 & | & 0\end{pmatrix}\Leftrightarrow\begin{pmatrix}-1 & 1 & | & 0 \\ 0 & 0 & | & 0\end{pmatrix}$\\	$-x1+x2=0$ ($x_2$ ist freie Variable)\\	$\Leftrightarrow x_1=x_2$\\	Lösung $\left\lbrace \begin{pmatrix}x_1 \\ x_2\end{pmatrix}\in \mathbb{R}^2 | x_1=x_2\right\rbrace$ alternativ $=<\begin{pmatrix}1 \\ 1\end{pmatrix}>_{\mathbb{R}}$\\	(oder wähle z.B. $x_2=1 \Rightarrow x_1=1$, also ist $\begin{pmatrix}1 \\ 1\end{pmatrix}$ Lösung, restliche Lösungen sind $<\begin{pmatrix}1 \\ 1\end{pmatrix}>_{\mathbb{R}}$)\\	$\mathrm{Eig}_A(\lambda_1)=\mathrm{Ker}\begin{pmatrix}-1 & 1 \\ -2 & 2\end{pmatrix}=<\begin{pmatrix}1 \\ 1\end{pmatrix}>$\\	x ist EV von A zum EW $\lambda_2 \Leftrightarrow x_\neq 0$ und $\begin{pmatrix}-2 & 1 \\ -2 & 1\end{pmatrix}x=\begin{pmatrix}0 \\ 0\end{pmatrix}$\\	$\mathrm{Eig}_A(\lambda_2)=\mathrm{Ker}\begin{pmatrix}-2 & 1 \\ -2 & 1\end{pmatrix}=<\begin{pmatrix}1 \\ 2\end{pmatrix}>$\\	zu Lösung von homogenen LGS: siehe Blatt im Moodle\end{itemize}% % % 8.5\subsection{Anwendungen}\begin{enumerate}	\item	Matrixpotenzen\\	Berechne $A^{2015}=\underbrace{A\cdot A\cdot \dots\cdot A}_{\text{2015 mal}}$ für $A=\begin{pmatrix}1 & 1 \\ -2 & 4\end{pmatrix}$ aus Bsp. 8.4\\	Definiere $S:=\begin{pmatrix}1 & 1 \\ 1 & 2\end{pmatrix}, \ \begin{pmatrix}1 \\ 1\end{pmatrix}$ EV zu $\lambda_1, \ \ \begin{pmatrix}1 \\ 2\end{pmatrix}$ EV zu $\lambda_2$\\	$S^{-1}\stackrel{7.10}{=}\frac{1}{\mathrm{det}S}\cdot \begin{pmatrix}2 & -1 \\ -1 & 1\end{pmatrix}=\begin{pmatrix}2 & -1 \\ -1 & 1\end{pmatrix}$\\	dann ist $A=S\cdot \underbrace{\begin{pmatrix}2 & 0 \\ 0 & 3\end{pmatrix}}_{D}\cdot S^{-1}$, D=Diagonalmatrix (stimmt, nachrechnen!)\\	$\Rightarrow A^{2015}=(SDS^{-1})^{2015} = (SD\underbrace{S^{-1})\cdot (S}_{E_2}DS^{-1})\cdot (SDS^{-1})\cdot \dots\cdot (SDS^{-1})$\\	$=S\cdot D^{2015}\cdot S^{-1}$\\	$=S\cdot \begin{pmatrix}2^{2015} & 0 \\ 0 & 3^{2015}\end{pmatrix}S^{-1}$		Mit lin. Abb./Darstellungsmatr. ausgedrückt:\\	$\varphi: \mathbb{R}^2\rightarrow\mathbb{R}^2$ mit $A=A_{\varphi}^{\mathcal{B}}=\begin{pmatrix}1 & 1 \\ -2 & 4\end{pmatrix}, \ \mathcal{B}$ kanon. Basis\\	Bezügl. Basis $\mathcal{B}'=\left(\begin{pmatrix}1 \\ 1\end{pmatrix},\begin{pmatrix}1 \\ 2\end{pmatrix}\right)$ hat Darstellungsmatrix Diagonalgestalt $A_{\varphi}^{\mathcal{B}'}=\begin{pmatrix}2 & 0 \\ 0 & 3\end{pmatrix}$		Bem.: nicht jede Darstellungsmatrix lässt sich auf Diagonalgestalt bringen, z.B. $A=\begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix}\in M_2(\mathbb{R})$, Drehung um $90^{\circ}$\\	$\mathrm{det}(A-\lambda E_2)=\mathrm{det}\begin{pmatrix}-\lambda & -1 \\ 1 & -\lambda\end{pmatrix}=\lambda^2+1$, keine nullstellen in $\mathbb{R}$, also keine reelen Eigenwerte!		\item	\begin{itemize}		\item Physik: Schwingungen, Eigenfrequenz, Tacoma Narrows Bridge		\item Googles PageRank-Algorithmus		\item Eigenfaces / Zähne ...\\		$\vdots$	\end{itemize}\end{enumerate}% % % 8.6\subsection{Bemerkung}Für $A\in M_n(K)$ ist $p_A(\lambda)=\mathrm{det}(A-\lambda E_n)=\mathrm{det}\begin{pmatrix}a_{11}-\lambda & a_{12} & \dots & a_{1m} \\ a_{21} & a_{22}-\lambda & \dots & \dots \\ \dots & \dots & \dots & \dots \\ a_{n1} & \dots & \dots & a_{nm}-\lambda\end{pmatrix}$\\ein Polynom vom Grad n (folgt aus Def. der Det.)\\Nullstellen von $p_A(\lambda)$ sind $\in W$ von A\\$\Rightarrow K=\mathbb{R}: \le n$ Eigenwerte\\$K?\mathbb{C}: $ genau n Eigenwerte (nicht notwendig verschieden)% % % 8.7\subsection{Definition: diagonalisierbar}\begin{enumerate}	\item	Eine Matrix $A\in M_n(K)$ heißt \textbf{diagonalisierbar}, wenn eine invertierbare Matrix $S\in M_n(K)$ existiert, so dass $A=SDS^{-1}$ gilt, wobei $D=\begin{pmatrix}\lambda_1 & \dots & 0 \\ \dots & \dots & \dots  \\ 0 & \dots & \lambda_n\end{pmatrix}$ Diagonalmatrix ist. (die $\lambda_i$ sind dann gerade die Eigenwerte von A, siehe 8.8)\\	(Bem.: Dann gilt auch $D=S^{-1}AS$)		\item	für lin. Abb:\\	Eine lin. Abb. $\varphi: V\rightarrow V$ heißt \textbf{diagonalisierbar}, falls $V$ eine Basis $\mathcal{B}$ aus Eigenvektoren (zur zugehörigen Darstellungsmatrix) besitzt, d.h. $A_\varphi^\mathcal{B}$ ist Diagonalmatrix.\end{enumerate}Ist jede Matrix diagonalisierbar? % % % 8.8\subsection{Satz: Spektralsatz}\begin{enumerate}	\item	$A\in M_n(K)$ ist diagonalisierbar $\Leftrightarrow$ Es gibt l.u. Eigenvektoren von A		\item	Besitzt A n verschiedene Eigenwerte, so ist A diagonalisierbar.\end{enumerate}\textbf{Beweis:}\begin{enumerate}	\item	A diagonalisierbar, d,h, $\exists S$ invertierbar mit\\	$S^{-1}AS=\begin{pmatrix}\lambda_1 & \dots & 0 \\ \dots & \dots & \dots  \\ 0 & \dots & \lambda_n\end{pmatrix} \Leftrightarrow  AS=S\cdot \begin{pmatrix}\lambda_1 & \dots & 0 \\ \dots & \dots & \dots  \\ 0 & \dots & \lambda_n\end{pmatrix}$		Sei $S=(s_1,\dots,s_n)$ (s=Spalten) Für die i-te Spalte $s_i$ von S gilt dann $A_{si}=\lambda_i\cdot s_i \ \ (i=1,\dots,n)$\\	Also ist $s_i$ Eigenvektor zum EW $\lambda_i$ von A\\	S ist invertierbar $\Leftrightarrow$ Spalten $s_1,\dots,s_n$ l.u. (Satz 6.8)		\item	zeige per Induktion, dass die zugehörigen Eigenvektoren linear unabhängig sind, Behauptung folgt dann aus (i)\\	\hspace*{13cm}$\square$\end{enumerate}% % % 8.9\subsection{Bemerkung zu 8.8 (ii)}Es gib auch diagonalisierbare Matrizen, die nicht n verschiedene Eigenwerte haben!\\z.B. $E_n$ ist bereits in Diagonalform\\$E_n=\begin{pmatrix}1 & \dots & 0\\ 0 & \ldots & 0\\ 0 & \dots & 1\end{pmatrix}=\underbrace{\begin{pmatrix}1 & \dots & 0\\ 0 & \ddots & 0\\ 0 & \dots & 1\end{pmatrix}}_{S}\underbrace{\begin{pmatrix}1 & \dots & 0\\ 0 & \ddots & 0\\ 0 & \dots & 1\end{pmatrix}}_{D}\underbrace{\begin{pmatrix}1 & \dots & 0\\ 0 & \ddots & 0\\ 0 & \dots & 1\end{pmatrix}}_{S^{-1}}$\\aber alle n Ew sind 1 (mit lin. Abb. ausgedrückt: $\mathrm{id}_v$ ist diagonalisierbar, $A_{\mathrm{id}_v}^B$ hat n gleiche EW)